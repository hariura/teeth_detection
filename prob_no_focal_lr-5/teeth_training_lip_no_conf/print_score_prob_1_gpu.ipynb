{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f3bbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 21:01:13.358689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 21:01:13.371420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 21:01:13.372194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 21:01:13.373157: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-11 21:01:13.374703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 21:01:13.375583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 21:01:13.376314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 21:01:13.998441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 21:01:13.999441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 21:01:14.000119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 21:01:14.000813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21843 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  \n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from yolov3.yolov4_config import Create_Yolo\n",
    "from yolov3.utils_config import load_yolo_weights, detect_image, image_preprocess, postprocess_boxes_excel, nms, draw_bbox\n",
    "from yolov3.configs_config import *\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "if YOLO_TYPE == \"yolov4\":\n",
    "    Darknet_weights = YOLO_V4_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V4_WEIGHTS\n",
    "if YOLO_TYPE == \"yolov3\":\n",
    "    Darknet_weights = YOLO_V3_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V3_WEIGHTS\n",
    "\n",
    "yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE)\n",
    "load_yolo_weights(yolo, Darknet_weights) # use Darknet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91c03f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f786852d2e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES)\n",
    "yolo.load_weights(\"./checkpoints/second/yolov3_custom\") # use keras weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ba2685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prt_loss(image_path ,yolo):\n",
    "    input_size = 416\n",
    "    iou_threshold = 0.45\n",
    "    \n",
    "    original_image      = cv2.imread(image_path)\n",
    "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "    pred_bbox = yolo.predict(image_data)\n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "    bboxes, pred_coor, pred_conf, pred_prob  = postprocess_boxes_excel(pred_bbox, original_image, input_size, 0.0)\n",
    "    classes = np.argmax(pred_prob, axis=-1)\n",
    "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
    "    argmax_score = np.argmax(scores)\n",
    "    max_score = np.max(scores)\n",
    "    print_conf, print_prob = pred_conf[argmax_score], pred_prob[argmax_score]\n",
    "    \n",
    "    return [max_score, print_conf, print_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b6c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GIoU(bboxes_1, bboxes_2):\n",
    "    # 1. calulate intersection over union\n",
    "    area_1 = (bboxes_1[2] - bboxes_1[0]) * (bboxes_1[3] - bboxes_1[1])\n",
    "    area_2 = (bboxes_2[2] - bboxes_2[0]) * (bboxes_2[3] - bboxes_2[1])\n",
    "    \n",
    "    intersection_wh = tf.minimum(bboxes_1[2:], bboxes_2[2:]) - tf.maximum(bboxes_1[ :2], bboxes_2[ :2])\n",
    "    intersection_wh = tf.maximum(intersection_wh, 0)\n",
    "    \n",
    "    intersection = intersection_wh[0] * intersection_wh[1]\n",
    "    union = (area_1 + area_2) - intersection\n",
    "    \n",
    "    ious = intersection / union\n",
    "    \n",
    "    # 2. (C - (A U B))/C\n",
    "    C_wh = tf.maximum(bboxes_1[2:], bboxes_2[2:]) - tf.minimum(bboxes_1[:2], bboxes_2[:2])\n",
    "    C_wh = C_wh\n",
    "    C = C_wh[0] * C_wh[1]\n",
    "\n",
    "    giou = ious - (C - union) / C\n",
    "    return giou, ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d139c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = glob(r\"teeth_including_lip_more/test/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c8a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r11 = glob(r\"teeth_including_lip_more/train/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dfea4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "r11 = sorted(r11)\n",
    "r1 = sorted(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa283f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r5 = glob(r\"/home/jh/Desktop/teeth/github_td/test2/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53212ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify\n",
    "coco_anomaly =  glob(r\"/home/jh/Desktop/teeth/github_td/val2017/*.jpg\")\n",
    "coco_anomaly = sorted(coco_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddec225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_85 = glob(r\"/home/jh/Desktop/teeth/github_td/ano/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c920ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "brace_path = r\"braces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb202ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "angled_path = r\"angled\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68afb01",
   "metadata": {},
   "source": [
    "### pred score save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bb63865",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = []\n",
    "valid_names = []\n",
    "test_names = []\n",
    "anomaly_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cc93775",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_names = []\n",
    "braces_names = []\n",
    "angle_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce152975",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(r11)):\n",
    "    train_names.append(os.path.basename(r11[i]))\n",
    "for i in range(len(r1)):\n",
    "    valid_names.append(os.path.basename(r1[i]))\n",
    "for i in range(len(r5)):\n",
    "    test_names.append(os.path.basename(r5[i]))\n",
    "for i in range(len(anomaly_85)):\n",
    "    anomaly_names.append(os.path.basename(anomaly_85[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46e56eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(coco_anomaly)):\n",
    "    coco_names.append(os.path.basename(coco_anomaly[i]))\n",
    "for i in range(len(os.listdir(brace_path))):\n",
    "    braces_names.append(os.path.basename(os.listdir(brace_path)[i]))\n",
    "for i in range(len(os.listdir(angled_path))):\n",
    "    angle_names.append(os.path.basename(os.listdir(angled_path)[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a60fceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "valid_score = []\n",
    "test_score = []\n",
    "anomaly_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15aecaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_score = []\n",
    "braces_score = []\n",
    "angle_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff893f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 21:01:25.838042: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8204\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(r11)):\n",
    "    aa =prt_loss(r11[i] ,yolo)\n",
    "    train_score.append(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f232c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(r1)):\n",
    "    aa =prt_loss(r1[i] ,yolo)\n",
    "    valid_score.append(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8363bdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(r5)):\n",
    "    aa =prt_loss(r5[i] ,yolo)\n",
    "    test_score.append(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2daf1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(anomaly_85)):\n",
    "    aa =prt_loss(anomaly_85[i] ,yolo)\n",
    "    anomaly_score.append(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cefcce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1295175/2699754950.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  raw_training = pd.DataFrame(data=np.array(train_score), index=[train_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])\n"
     ]
    }
   ],
   "source": [
    "raw_training = pd.DataFrame(data=np.array(train_score), index=[train_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bf34236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1295175/1602272338.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  raw_valid = pd.DataFrame(data=np.array(valid_score), index=[valid_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])\n"
     ]
    }
   ],
   "source": [
    "raw_valid = pd.DataFrame(data=np.array(valid_score), index=[valid_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cdc7870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1295175/1281917758.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  raw_test = pd.DataFrame(data=np.array(test_score), index=[test_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])\n"
     ]
    }
   ],
   "source": [
    "raw_test = pd.DataFrame(data=np.array(test_score), index=[test_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59ced0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1295175/911882621.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  raw_anomaly = pd.DataFrame(data=np.array(anomaly_score), index=[anomaly_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])\n"
     ]
    }
   ],
   "source": [
    "raw_anomaly = pd.DataFrame(data=np.array(anomaly_score), index=[anomaly_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "391d22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(coco_anomaly)):\n",
    "    aa =prt_loss(coco_anomaly[i] ,yolo)\n",
    "    coco_score.append(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da5fc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(os.listdir(angled_path))):\n",
    "    aa =prt_loss(os.path.join(angled_path, os.listdir(angled_path)[i]) ,yolo)\n",
    "    angle_score.append(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a33bb72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(os.listdir(brace_path))):\n",
    "    aa =prt_loss(os.path.join(brace_path, os.listdir(brace_path)[i]) ,yolo)\n",
    "    braces_score.append(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a66c53c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1295175/794488856.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  raw_coco= pd.DataFrame(data=np.array(coco_score), index=[coco_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])\n"
     ]
    }
   ],
   "source": [
    "raw_coco= pd.DataFrame(data=np.array(coco_score), index=[coco_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0a40d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1295175/3543986322.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  raw_anlge= pd.DataFrame(data=np.array(angle_score), index=[angle_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])\n"
     ]
    }
   ],
   "source": [
    "raw_anlge= pd.DataFrame(data=np.array(angle_score), index=[angle_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96f5b8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1295175/928199419.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  raw_braces= pd.DataFrame(data=np.array(braces_score), index=[braces_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])\n"
     ]
    }
   ],
   "source": [
    "raw_braces= pd.DataFrame(data=np.array(braces_score), index=[braces_names], columns=[\"score\",\"pred_conf\",\"pred_prob\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ec407d",
   "metadata": {},
   "source": [
    "## GIOU(must change when change txt file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85696726",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"model_data/lip_more_train.txt\", \"r\")\n",
    "lip_train = file.readlines()\n",
    "file.close()\n",
    "file = open(\"model_data/lip_more_validation.txt\", \"r\")\n",
    "lip_valid = file.readlines()\n",
    "file.close()\n",
    "lip_train = sorted(lip_train)\n",
    "lip_valid = sorted(lip_valid)\n",
    "\n",
    "# file = open(\"model_data/no_lip_more_train.txt\", \"r\")\n",
    "# no_lip_train = file.readlines()\n",
    "# file.close()\n",
    "# file = open(\"model_data/no_lip_more_validation.txt\", \"r\")\n",
    "# no_lip_valid = file.readlines()\n",
    "# file.close()\n",
    "# no_lip_train = sorted(no_lip_train)\n",
    "# no_lip_valid = sorted(no_lip_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d727d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_train = []\n",
    "GT_valid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8da4782",
   "metadata": {},
   "outputs": [],
   "source": [
    "giou_ious_list_train = []\n",
    "giou_ious_list_valid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d56da965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GT add\n",
    "for i in range(len(r11)):\n",
    "    bb = lip_train[i].split()[1].split(\",\")[0:4]\n",
    "    bb = [int(item) for item in bb]\n",
    "    GT_train.append(bb)\n",
    "for i in range(len(r1)):\n",
    "    bb = lip_valid[i].split()[1].split(\",\")[0:4]\n",
    "    bb = [int(item) for item in bb]\n",
    "    GT_valid.append(bb)\n",
    "\n",
    "# #GT add\n",
    "# for i in range(len(r11)):\n",
    "#     bb = no_lip_train[i].split()[1].split(\",\")[0:4]\n",
    "#     bb = [int(item) for item in bb]\n",
    "#     GT_train.append(bb)\n",
    "# for i in range(len(r1)):\n",
    "#     bb = no_lip_valid[i].split()[1].split(\",\")[0:4]\n",
    "#     bb = [int(item) for item in bb]\n",
    "#     GT_valid.append(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc0ef0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "for i in range(len(r11)):\n",
    "    image, bboxes = detect_image(yolo, r11[i], \"\", input_size=YOLO_INPUT_SIZE, show=False, score_threshold=0.1, CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    if len(bboxes) == 0 :\n",
    "        giou_ious_list_train.append([0,0])\n",
    "    else :\n",
    "        giou,ious = GIoU(np.array(GT_train[i]), bboxes[0][:4])\n",
    "        giou_ious_list_train.append([giou,ious])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45409d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "for i in range(len(r1)):\n",
    "    image, bboxes = detect_image(yolo, r1[i], \"\", input_size=YOLO_INPUT_SIZE,score_threshold=0.1, show=False, CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    if len(bboxes) == 0 :\n",
    "        giou_ious_list_valid.append([0,0])\n",
    "    else :\n",
    "        giou,ious = GIoU(np.array(GT_valid[i]), bboxes[0][:4])\n",
    "        giou_ious_list_valid.append([giou,ious])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dba4c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_giou = pd.DataFrame(data=np.array(giou_ious_list_train), index=[train_names], columns=[\"giou\", \"iou\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7302bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_valid_giou = pd.DataFrame(data=np.array(giou_ious_list_valid), index=[valid_names], columns=[\"giou\", \"iou\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e15a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_join = pd.merge(raw_training,raw_training_giou, left_index=True, right_index = True, \n",
    "                         how =\"outer\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10cca578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_join = pd.merge(raw_valid,raw_valid_giou, left_index=True, right_index = True, \n",
    "                         how =\"outer\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6fc8f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  34  130  161  189  241  337  466  474  600  646  769  775  860  878\n",
      "  975  995 1016 1021 1076 1082 1184 1267 1275 1363 1478 1500 1528 1585\n",
      " 1685 1806 1899 1955 1981 2041 2047 2061 2363 2391 2433 2435 2556 2558\n",
      " 2612 2613 2734 2747 2824 2888 2904 2919 3005 3073 3092 3152 3171 3202\n",
      " 3342 3385 3444 3461 3556 3772 3798 3843 3890 3943 4014 4117 4297 4426\n",
      " 4551 4555 4658 4798 4843 4911]\n"
     ]
    }
   ],
   "source": [
    "#modify \n",
    "coco_anomaly =  glob(r\"/home/jh/Desktop/teeth/github_td/val2017/*.jpg\")\n",
    "coco_anomaly = sorted(coco_anomaly)\n",
    "np.random.seed(42)\n",
    "a = np.random.randint(5000, size =76)\n",
    "a = np.sort(a)\n",
    "print(a)\n",
    "anomaly_76 = [coco_anomaly[i] for i in a]\n",
    "remove_name = [os.path.basename(i) for i in anomaly_76]\n",
    "raw_coco = raw_coco.drop(remove_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "998e46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify\n",
    "os.mkdir(\"./infer_2_gpu\")\n",
    "xlxs_dir='./infer_2_gpu/___final.xlsx' #경로 및 파일명 설정\n",
    "with pd.ExcelWriter(xlxs_dir) as writer:\n",
    "    df_training_join.to_excel(writer, sheet_name = 'training_data') #raw_data1 시트에 저장\n",
    "    df_valid_join.to_excel(writer, sheet_name = 'valid_data') #raw_data2 시트에 저장\n",
    "    raw_test.to_excel(writer, sheet_name = 'test_data') #raw_data2 시트에 저장\n",
    "    raw_anomaly.to_excel(writer, sheet_name = 'anomaly_data') #raw_data2 시트에 저장\n",
    "    raw_coco.to_excel(writer, sheet_name = 'coco_data') #raw_data1 시트에 저장\n",
    "    raw_anlge.to_excel(writer, sheet_name = 'angle_data') #raw_data2 시트에 저장\n",
    "    raw_braces.to_excel(writer, sheet_name = 'braces_data') #raw_data2 시트에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1cbf5",
   "metadata": {},
   "source": [
    "#  test2 replace old_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a74706a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a98c5a",
   "metadata": {},
   "source": [
    "# remove overlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f97af35",
   "metadata": {},
   "source": [
    "# AUC 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "200619fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_excel(xlxs_dir, sheet_name=\"test_data\", engine='openpyxl')\n",
    "coco_df = pd.read_excel(xlxs_dir, sheet_name=\"coco_data\", engine='openpyxl')\n",
    "angle_df = pd.read_excel(xlxs_dir, sheet_name=\"angle_data\", engine='openpyxl')\n",
    "braces_df = pd.read_excel(xlxs_dir, sheet_name=\"braces_data\", engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3321a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_score = [i for i in test_df[\"pred_conf\"]]\n",
    "coco_pred_score=  [i for i in coco_df[\"pred_conf\"]]\n",
    "angle_pred_score =  [i for i in angle_df[\"pred_conf\"]]\n",
    "braces_pred_score =  [i for i in braces_df[\"pred_conf\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29153170",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1]*len(test_pred_score) +  [0]*len(coco_pred_score)+ [0]*len(angle_pred_score) +[1]*len(braces_pred_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6593cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(test_pred_score +coco_pred_score +angle_pred_score+braces_pred_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e1182dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mauc(fpr, tpr)\n",
      "File \u001b[0;32m~/anaconda3/envs/teeth_3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/teeth_3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:755\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    753\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n\u001b[1;32m    754\u001b[0m assert_all_finite(y_true)\n\u001b[0;32m--> 755\u001b[0m \u001b[43massert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;66;03m# Filter out zero-weighted samples, as they should not impact the result\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/teeth_3/lib/python3.8/site-packages/sklearn/utils/validation.py:190\u001b[0m, in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_all_finite\u001b[39m(\n\u001b[1;32m    165\u001b[0m     X,\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    170\u001b[0m ):\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;124;03m\"\"\"Throw a ValueError if X contains NaN or infinity.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m        documentation.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/teeth_3/lib/python3.8/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d6c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a1a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color=\"darkorange\",\n",
    "    lw=lw,\n",
    "    label=\"ROC curve (area = %0.2f)\" % roc_auc,\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic example\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred)):\n",
    "    if pred[i]>0.8 :\n",
    "        pred[i]=1\n",
    "    else:\n",
    "        pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = metrics.confusion_matrix(y, pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8dcb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify\n",
    "import seaborn as sns\n",
    "cf_matrix = metrics.confusion_matrix(y, pred)\n",
    "group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "# group_percentages = [“{0:.2%}”.format(value) for value in\n",
    "#                      cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\" for v1, v2  in zip(group_names,group_counts)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap='Blues')\n",
    "plt.savefig(\"./infer_2_gpu/confusion_matrix.jpg\",bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32529afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
