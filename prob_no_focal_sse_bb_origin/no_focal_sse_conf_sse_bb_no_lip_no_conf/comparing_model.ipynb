{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f196bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from yolov3.yolov4_config import Create_Yolo\n",
    "from yolov3.utils_config import load_yolo_weights, detect_image\n",
    "from yolov3.configs_config import *\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "if YOLO_TYPE == \"yolov4\":\n",
    "    Darknet_weights = YOLO_V4_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V4_WEIGHTS\n",
    "if YOLO_TYPE == \"yolov3\":\n",
    "    Darknet_weights = YOLO_V3_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V3_WEIGHTS\n",
    "\n",
    "yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE)\n",
    "load_yolo_weights(yolo, Darknet_weights) # use Darknet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b91ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES)\n",
    "yolo.load_weights(\"./checkpoints/frist/yolov3_custom\") # use keras weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be4194",
   "metadata": {},
   "source": [
    "# image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad972ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = glob(r\"teeth_including_lip_more\\train/*.xml\")\n",
    "te = glob(r\"teeth_including_lip_more\\test/*.xml\")\n",
    "\n",
    "print(\"train data : {}\".format(len(tr)))\n",
    "print(\"test data : {}\".format(len(te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3883f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = glob(r\"teeth_including_lip_more\\test/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "r11 = glob(r\"teeth_including_lip_more\\train/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 =  glob(r\"anomaly_data/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "r3 =  glob(r\"crop_anomaly/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "r4 =  glob(r\"use_image_poster\\real_anomaly/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # in dahun computer \n",
    "# coco_anomaly =  glob(r\"C:\\Users\\NA_team2\\TensorFlow-2.x-YOLOv3\\TensorFlow-2.x-YOLOv3\\val2017/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_anomaly =  glob(r\"C:\\Users\\NA_team_1\\Desktop\\val2017\\*.jpg\")\n",
    "np.random.seed(42)\n",
    "a = np.random.randint(5000, size =76)\n",
    "a = np.sort(a)\n",
    "print(a)\n",
    "anomaly_76 = [coco_anomaly[i] for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f6c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_center_crop = glob(r\"anomaly_crop_done/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e2780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# braces =  glob(r\"C:\\Users\\NA_team_1\\Desktop\\GitHub\\TensorFlow-2.x-YOLOv3\\braces/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb390967",
   "metadata": {},
   "outputs": [],
   "source": [
    "brace_path = r\"braces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd27debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "angled_path = r\"angled\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f97dc02",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4880ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,30))\n",
    "#for i in range(18):\n",
    "#    plt.subplot(6,3,i+1)\n",
    "plt.figure(figsize=(15,10))\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    image, bboxes = detect_image(yolo, r11[i], \"\", input_size=YOLO_INPUT_SIZE, show=False, CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    if len(bboxes) == 0 :\n",
    "        plt.title('no object')\n",
    "        plt.axis('off')\n",
    "    else :\n",
    "        plt.title('score {0:2f}'.format(bboxes[0][4]))\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd233f",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22360ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,45))\n",
    "for i in range(85):\n",
    "    plt.subplot(29,3,i+1)\n",
    "# plt.figure(figsize=(15,10))\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2,3,i+1)\n",
    "    image, bboxes = detect_image(yolo, r1[i], \"\", input_size=YOLO_INPUT_SIZE, show=False, CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    if len(bboxes) == 0 :\n",
    "        plt.title('no object')\n",
    "        plt.axis('off')\n",
    "    else :\n",
    "        plt.title('score {0:2f}'.format(bboxes[0][4]))\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae3926",
   "metadata": {},
   "source": [
    "# anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7698013",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,30))\n",
    "for i in range(18):\n",
    "    plt.subplot(7,3,i+1)\n",
    "# plt.figure(figsize=(15,10))\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2,3,i+1)\n",
    "    image, bboxes = detect_image(yolo, r2[i], \"\", input_size=YOLO_INPUT_SIZE, show=False, score_threshold = 0.3,CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    if len(bboxes) == 0 :\n",
    "        plt.title('no object')\n",
    "        plt.axis('off')\n",
    "    else :\n",
    "        plt.title('score {0:2f}'.format(bboxes[0][4]))\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb0c0c4",
   "metadata": {},
   "source": [
    "# crop anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc30a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,30))\n",
    "for i in range(len(r3)):\n",
    "    plt.subplot(5,2,i+1)\n",
    "    image, bboxes = detect_image(yolo, r3[i], \"\", input_size=YOLO_INPUT_SIZE, show=False, score_threshold = 0.5 , CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    if len(bboxes) == 0 :\n",
    "        plt.title('no object  \\n size: {}'.format(cv2.imread(r3[i]).shape[0:2]))\n",
    "        plt.axis('off')\n",
    "    else :\n",
    "        plt.title('score : {0:2f} \\n size: {1} '.format(bboxes[0][4], cv2.imread(r3[i]).shape[0:2]))\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3287f5",
   "metadata": {},
   "source": [
    "# coco 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,60))\n",
    "for i in range(76):\n",
    "    plt.subplot(26,3,i+1)\n",
    "# plt.figure(figsize=(15,10))\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2,3,i+1)\n",
    "    image, bboxes = detect_image(yolo, anomaly_76[i], \"\", input_size=YOLO_INPUT_SIZE, show=False, CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    if len(bboxes) == 0 :\n",
    "        plt.title('no object')\n",
    "        plt.axis('off')\n",
    "    else :\n",
    "        plt.title('score {0:2f}'.format(bboxes[0][4]))\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f325b",
   "metadata": {},
   "source": [
    "# coco 76 center crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb8e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,60))\n",
    "for i in range(76):\n",
    "    plt.subplot(26,3,i+1)\n",
    "# plt.figure(figsize=(15,10))\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2,3,i+1)\n",
    "    image, bboxes = detect_image(yolo, coco_center_crop[i], \"\", input_size=YOLO_INPUT_SIZE, show=False, CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    if len(bboxes) == 0 :\n",
    "        plt.title('no object')\n",
    "        plt.axis('off')\n",
    "    else :\n",
    "        plt.title('score {0:2f}'.format(bboxes[0][4]))\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea85620",
   "metadata": {},
   "source": [
    "# braces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabdddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it contain png files\n",
    "plt.figure(figsize=(15,30))\n",
    "for i in range(14):\n",
    "    plt.subplot(7,3,i+1)\n",
    "# plt.figure(figsize=(15,10))\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2,3,i+1)\n",
    "    image, bboxes = detect_image(yolo, os.path.join(brace_path, os.listdir(brace_path)[i]), \"\", input_size=YOLO_INPUT_SIZE, show=False, score_threshold = 0.3,CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    if len(bboxes) == 0 :\n",
    "        plt.title('no object')\n",
    "        plt.axis('off')\n",
    "    else :\n",
    "        plt.title('score {0:2f}'.format(bboxes[0][4]))\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d1e5a8",
   "metadata": {},
   "source": [
    "# angle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc96e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,30))\n",
    "for i in range(14):\n",
    "    plt.subplot(7,3,i+1)\n",
    "# plt.figure(figsize=(15,10))\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2,3,i+1)\n",
    "    image, bboxes = detect_image(yolo, os.path.join(angled_path, os.listdir(angled_path)[i]), \"\", input_size=YOLO_INPUT_SIZE, show=False, score_threshold = 0.3,CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)\n",
    "    if len(bboxes) == 0 :\n",
    "        plt.title('no object')\n",
    "        plt.axis('off')\n",
    "    else :\n",
    "        plt.title('score {0:2f}'.format(bboxes[0][4]))\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fafc603",
   "metadata": {},
   "source": [
    "# score evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ea098",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = [ ]\n",
    "test_score = []\n",
    "anomaly_score = []\n",
    "anomaly_i=[]\n",
    "center_anomaly_score = []\n",
    "center_anomaly_i = []\n",
    "full_coco_anomaly_score = []\n",
    "full_coco_anomaly_i=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad4a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train \n",
    "for i in range(len(r11)):\n",
    "    image, bboxes = detect_image(yolo, r11[i], \"\", input_size=YOLO_INPUT_SIZE, show=False, score_threshold = 0.3,CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    train_score.append(bboxes[0][4])\n",
    "print(\"mean: {0:7f}, val : {1:7f}, min : {2:2f}\".format(np.mean(train_score), np.var(train_score), np.min(train_score))  )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "for i in range(len(r1)):\n",
    "    image, bboxes = detect_image(yolo, r1[i], \"\", input_size=YOLO_INPUT_SIZE, show=False, score_threshold = 0.3, CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    test_score.append(bboxes[0][4])\n",
    "#     print(i ,bboxes)\n",
    "print(\"mean: {0:7f}, val : {1:7f}, min : {2:2f}\".format(np.mean(test_score), np.var(test_score) , np.min(test_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e92d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anomaly 85\n",
    "anomaly_85 = anomaly_76 + r2[-9:]\n",
    "for i in range(len(anomaly_85)):\n",
    "    image, bboxes = detect_image(yolo, anomaly_85[i], \"\", input_size=YOLO_INPUT_SIZE, show=False, score_threshold = 0.3,CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    if len(bboxes)!=0:\n",
    "        anomaly_score.append(bboxes[0][4])\n",
    "        anomaly_i.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0ddf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coco anomaly full\n",
    "for i in range(len(coco_anomaly)):\n",
    "    image, bboxes = detect_image(yolo, coco_anomaly[i], \"\", input_size=YOLO_INPUT_SIZE, show=False, score_threshold = 0.3,CLASSES=TRAIN_CLASSES, rectangle_colors=(255,0,0))\n",
    "    if len(bboxes)!=0:\n",
    "        full_coco_anomaly_score.append(bboxes[0][4])\n",
    "        full_coco_anomaly_i.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1331e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(full_coco_anomaly_score)):\n",
    "    print(full_coco_anomaly_score[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9377bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in full_coco_anomaly_score:\n",
    "    if i>0.8:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
